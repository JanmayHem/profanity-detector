# Profanity Detector
A python based ML model, which detects profane language and returns true or false with respect to a social media environment (yeah, have to consider things like free speech shm).  

This is under development. [================>. . . .]

## How to use
1) Download all .py files or [clone the repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository).
2) Download all files in the Input Files and arrange them [accordingly](https://github.com/JanmayHem/profanity-detector/blob/main/Input%20Files/README.md).
<br>&emsp;• Alternatively, you can access the same input files from [Kaggle](https://www.kaggle.com/code/psvenom/balls/data).
3) Run the \_profanity_.py file. 
<br>&emsp;• This will read all the data, preprocess it, form a proper format, and feed the model. 
<br>&emsp;• Then the model is saved.
4) Run the data-csv-generator.py files.
<br>&emsp;• This makes the csv file which we will use to compare with the inputs.
5) The main file is where the function is, which takes in the Statement in String form and returns True or false based on the profanity score given by the model trained.

## Details 
Lorem Ipsum

## Why this project?
Lorem Ipsum

## Contributing
• Pull requests are welcome, why else we on GitHub for eh. 

• For major changes, please open an issue first
to discuss what you would like to change. Please make sure to update tests as appropriate. 

• Aiming to make this a proper Python Library on PyPI.

• Open to discussions as well! 

## License

This repository comes under the [MIT License](https://choosealicense.com/licenses/mit/). Kindly check all the details.

-- <br>
Made with :heart: by [@JanmayHem](https://github.com/JanmayHem) 
